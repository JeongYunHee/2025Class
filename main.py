import streamlit as st
import pandas as pd

# --- ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ìƒë‹´ ì¼ì • ì¡°íšŒ", page_icon="ğŸ“…")
st.title("ğŸ“š í•™ìƒ ë° í•™ë¶€ëª¨ ìƒë‹´ ì¼ì • ì¡°íšŒ")
st.caption("ì´ë¦„ê³¼ íœ´ëŒ€í° ë²ˆí˜¸ ë’¤ 4ìë¦¬ë¥¼ ì…ë ¥í•˜ë©´ ìƒë‹´ ì¼ì‹œë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# --- Google Sheets URL ---
SHEET_URL = st.secrets.get("SHEET_URL", "")

if not SHEET_URL:
    st.warning("âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ë§í¬ ë“±ë¡í•˜ì„¸ìš”. ")
    st.stop()

@st.cache_data(ttl=300)
def load_csv(url: str) -> pd.DataFrame:
    df = pd.read_csv(url)
    if df.columns[0].strip().lower() != "time":
        df = df.rename(columns={df.columns[0]: "time"})
    df.columns = [str(c).strip() for c in df.columns]
    df = df[~df["time"].astype(str).str.contains("ì ì‹¬")]
    return df.reset_index(drop=True)

try:
    df = load_csv(SHEET_URL)
except Exception as e:
    st.error(f"âŒ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    st.stop()

# --- ì‚¬ìš©ì ì…ë ¥ ---
col1, col2 = st.columns(2)
with col1:
    name_input = st.text_input("ğŸ‘¤ ì´ë¦„ (í•™ìƒ ë˜ëŠ” í•™ë¶€ëª¨)", placeholder="ì˜ˆ: ê¹€í•˜ë‚˜").strip()
with col2:
    num_input = st.text_input("ğŸ”¢ íœ´ëŒ€í° ë²ˆí˜¸ (ë’¤ 4ìë¦¬)", placeholder="ì˜ˆ: 1234").strip()


def find_match(df: pd.DataFrame, name: str, num: str):
    """ì´ë¦„ê³¼ ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ëŠ” ì…€(í•™ìƒ ë˜ëŠ” í•™ë¶€ëª¨)ì„ ì°¾ìŒ."""
    if not name or not num:
        return []

    hits = []
    # ë‘ ê°€ì§€ í˜•íƒœ (í•™ìƒ, í•™ë¶€ëª¨) ëª¨ë‘ ì°¾ê¸°
    targets = [f"{name} {num}", f"#{name} {num}"]
    date_cols = df.columns[1:]

    for date_col in date_cols:
        col_series = df[date_col].astype(str).fillna("").str.strip()

        for idx, cell in col_series.items():
            cell_str = str(cell).strip()
            if not cell_str or cell_str.lower() in ["nan", "none"]:
                continue

            tokens = [t.strip() for t in
                      pd.Series(cell_str.replace("ï¼", "/").replace("ï¼Œ", ","))
                      .astype(str)
                      .str.split(r"[,/]").explode().tolist()]

            for token in tokens:
                clean_token = token.replace("*", "").strip()

                for target in targets:
                    if clean_token == target:
                        has_star = "*" in token
                        is_parent = target.startswith("#")
                        hits.append((
                            str(date_col).strip(),
                            str(df.loc[idx, "time"]).strip(),
                            target,
                            has_star,
                            is_parent
                        ))
    return hits


# --- ê²°ê³¼ í‘œì‹œ ---
if name_input and num_input:
    matches = find_match(df, name_input, num_input)

    if matches:
        st.success(f"âœ… {name_input} ({num_input})ë‹˜ì˜ ìƒë‹´ ì¼ì •ì…ë‹ˆë‹¤.")
        for (date, time_, who, has_star, is_parent) in matches:
            location = "ì „í™” ìƒë‹´" if has_star else "ì»´í“¨í„°ì‹¤2"
            role = "í•™ë¶€ëª¨" if is_parent else "í•™ìƒ"
            st.markdown(
                f"""
                ---
                ğŸ‘¤ **êµ¬ë¶„:** {role}  
                ğŸ—“ **ìƒë‹´ ì¼ì‹œ:** {date} {time_}  
                ğŸ“ **ìƒë‹´ ì¥ì†Œ:** {location}  
                â˜ï¸ *ì‹œê°„ ë° ì¥ì†ŒëŠ” ë³€ë™ë  ìˆ˜ ìˆìœ¼ë‹ˆ ë‹¹ì¼ ì „í™” ê¼­! í™•ì¸í•˜ì„¸ìš”.*
                """
            )
    else:
        st.info("ğŸ” ì…ë ¥í•œ ì´ë¦„ê³¼ ë²ˆí˜¸ê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì¼ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
elif name_input or num_input:
    st.warning("âš ï¸ ì´ë¦„ê³¼ ë²ˆí˜¸ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì•¼ ê²€ìƒ‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
